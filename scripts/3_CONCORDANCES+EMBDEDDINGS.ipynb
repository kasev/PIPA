{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import Embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint variable has been configured to: https://sciencedata.dk/files/\n"
     ]
    }
   ],
   "source": [
    "# to communicate with google spreadsheet...\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2 import service_account # based on google-auth library\n",
    "import sddk\n",
    "\n",
    "s = sddk.cloudSession(\"sciencedata.dk\")\n",
    "# establish connection with gogglesheets...\n",
    "file_data = s.read_file(\"https://sciencedata.dk/files/ServiceAccountsKey.json\", \"dict\") # or load it from a local storage: json.load(open(\"../../ServiceAccountsKey.json\", \"r\"))\n",
    "credentials = service_account.Credentials.from_service_account_info(file_data)\n",
    "gc = gspread.Client(auth=credentials.with_scopes(['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']))\n",
    "PIPA_data = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1rV4t0_UV_wcx--UAHVwkqB8Wa_5n9mnpV05yGG1OHqk/edit?usp=sharing\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                          filename      author                  title  \\\n1  tlg0003.tlg001.perseus-grc2.xml  Thucydides  The Peloponnesian War   \n6  tlg0006.tlg001.perseus-grc2.xml   Euripides                Cyclops   \n7  tlg0006.tlg004.perseus-grc2.xml   Euripides             Ἡρακλεῖδαι   \n8  tlg0006.tlg005.perseus-grc2.xml   Euripides              Ἱππόλυτος   \n9  tlg0006.tlg006.perseus-grc2.xml   Euripides              Ἀνδρομάχη   \n\n   wordcount author_id          doc_id raw_date  date_avr   date_probs  \\\n1     150118   tlg0003  tlg0003.tlg001   5 B.C.      -4.5  {'-4.5': 1}   \n6       4141   tlg0006  tlg0006.tlg001   5 B.C.      -4.5  {'-4.5': 1}   \n7       6272   tlg0006  tlg0006.tlg004   5 B.C.      -4.5  {'-4.5': 1}   \n8       8257   tlg0006  tlg0006.tlg005   5 B.C.      -4.5  {'-4.5': 1}   \n9       7397   tlg0006  tlg0006.tlg006   5 B.C.      -4.5  {'-4.5': 1}   \n\n   date_manual  ...                                            lemmata  \\\n1         -4.5  ...  [θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελο...   \n6         -4.5  ...  [Βρόμιος, ἔχω, πόνος, χὥτʼ, ἥβη, ἐμός, εὐσθενέ...   \n7         -4.5  ...  [ποτός, εἰμί, οὗτος, δεδογμένον, δίκαιος, φύω,...   \n8         -4.5  ...  [πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις, ...   \n9         -4.5  ...  [Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πολ...   \n\n  lemmata_wordcount subcorpus  \\\n1             71863      None   \n6              2535      None   \n7              3545      None   \n8              4898      None   \n9              4420      None   \n\n                                        lemmata_repl  \\\n1  [θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελο...   \n6  [Βρόμιος, ἔχω, πόνο*, χὥτʼ, ἥβη, ἐμός, εὐσθενέ...   \n7  [ποτός, εἰμί, οὗτος, δεδογμένον, δίκαιος, φύω,...   \n8  [πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις, ...   \n9  [Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πολ...   \n\n                           lemmatized_sentences_repl count_πόνο*  count_ὀδύν*  \\\n1  [[θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελ...          31            0   \n6  [[Βρόμιος, ἔχω, πόνο*, χὥτʼ, ἥβη, ἐμός, εὐσθεν...           7            0   \n7  [[ποτός, εἰμί, οὗτος, δεδογμένον], [δίκαιος, φ...          11            0   \n8  [[πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις,...           8            3   \n9  [[Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πο...           5            0   \n\n  count_ἄλγ* count_λύπ*                                          conc_lype  \n1          6         25  [[μέγας, κινδυνεύοντας, δέχομαι, ἀείμνηστος, μ...  \n6          0          1  [[βοτόν, οὔτις, θύω, θεός, μέγας, γαστήρ, δαίμ...  \n7          1          2  [[εἰμί, πολύς, χαίρω, δυσφημέω, ἅζομαι, θέα, σ...  \n8          8          8  [[κοιτάζω, λέχος, σός, ναυβάτης, τὶς, πλέω, κρ...  \n9          7          4  [[Τροία, πράσσω, μηδείς, ὅδε, αὐχέω, πράσσω, δ...  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>author</th>\n      <th>title</th>\n      <th>wordcount</th>\n      <th>author_id</th>\n      <th>doc_id</th>\n      <th>raw_date</th>\n      <th>date_avr</th>\n      <th>date_probs</th>\n      <th>date_manual</th>\n      <th>...</th>\n      <th>lemmata</th>\n      <th>lemmata_wordcount</th>\n      <th>subcorpus</th>\n      <th>lemmata_repl</th>\n      <th>lemmatized_sentences_repl</th>\n      <th>count_πόνο*</th>\n      <th>count_ὀδύν*</th>\n      <th>count_ἄλγ*</th>\n      <th>count_λύπ*</th>\n      <th>conc_lype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>tlg0003.tlg001.perseus-grc2.xml</td>\n      <td>Thucydides</td>\n      <td>The Peloponnesian War</td>\n      <td>150118</td>\n      <td>tlg0003</td>\n      <td>tlg0003.tlg001</td>\n      <td>5 B.C.</td>\n      <td>-4.5</td>\n      <td>{'-4.5': 1}</td>\n      <td>-4.5</td>\n      <td>...</td>\n      <td>[θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελο...</td>\n      <td>71863</td>\n      <td>None</td>\n      <td>[θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελο...</td>\n      <td>[[θουκυδίδης, Ἀθηναῖος, συγγράφω, πόλεμος, Πελ...</td>\n      <td>31</td>\n      <td>0</td>\n      <td>6</td>\n      <td>25</td>\n      <td>[[μέγας, κινδυνεύοντας, δέχομαι, ἀείμνηστος, μ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tlg0006.tlg001.perseus-grc2.xml</td>\n      <td>Euripides</td>\n      <td>Cyclops</td>\n      <td>4141</td>\n      <td>tlg0006</td>\n      <td>tlg0006.tlg001</td>\n      <td>5 B.C.</td>\n      <td>-4.5</td>\n      <td>{'-4.5': 1}</td>\n      <td>-4.5</td>\n      <td>...</td>\n      <td>[Βρόμιος, ἔχω, πόνος, χὥτʼ, ἥβη, ἐμός, εὐσθενέ...</td>\n      <td>2535</td>\n      <td>None</td>\n      <td>[Βρόμιος, ἔχω, πόνο*, χὥτʼ, ἥβη, ἐμός, εὐσθενέ...</td>\n      <td>[[Βρόμιος, ἔχω, πόνο*, χὥτʼ, ἥβη, ἐμός, εὐσθεν...</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[[βοτόν, οὔτις, θύω, θεός, μέγας, γαστήρ, δαίμ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>tlg0006.tlg004.perseus-grc2.xml</td>\n      <td>Euripides</td>\n      <td>Ἡρακλεῖδαι</td>\n      <td>6272</td>\n      <td>tlg0006</td>\n      <td>tlg0006.tlg004</td>\n      <td>5 B.C.</td>\n      <td>-4.5</td>\n      <td>{'-4.5': 1}</td>\n      <td>-4.5</td>\n      <td>...</td>\n      <td>[ποτός, εἰμί, οὗτος, δεδογμένον, δίκαιος, φύω,...</td>\n      <td>3545</td>\n      <td>None</td>\n      <td>[ποτός, εἰμί, οὗτος, δεδογμένον, δίκαιος, φύω,...</td>\n      <td>[[ποτός, εἰμί, οὗτος, δεδογμένον], [δίκαιος, φ...</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[[εἰμί, πολύς, χαίρω, δυσφημέω, ἅζομαι, θέα, σ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>tlg0006.tlg005.perseus-grc2.xml</td>\n      <td>Euripides</td>\n      <td>Ἱππόλυτος</td>\n      <td>8257</td>\n      <td>tlg0006</td>\n      <td>tlg0006.tlg005</td>\n      <td>5 B.C.</td>\n      <td>-4.5</td>\n      <td>{'-4.5': 1}</td>\n      <td>-4.5</td>\n      <td>...</td>\n      <td>[πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις, ...</td>\n      <td>4898</td>\n      <td>None</td>\n      <td>[πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις, ...</td>\n      <td>[[πολύς, βροτός, ἀνώνυμος, θεά, καλέω, Κύπρις,...</td>\n      <td>8</td>\n      <td>3</td>\n      <td>8</td>\n      <td>8</td>\n      <td>[[κοιτάζω, λέχος, σός, ναυβάτης, τὶς, πλέω, κρ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>tlg0006.tlg006.perseus-grc2.xml</td>\n      <td>Euripides</td>\n      <td>Ἀνδρομάχη</td>\n      <td>7397</td>\n      <td>tlg0006</td>\n      <td>tlg0006.tlg006</td>\n      <td>5 B.C.</td>\n      <td>-4.5</td>\n      <td>{'-4.5': 1}</td>\n      <td>-4.5</td>\n      <td>...</td>\n      <td>[Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πολ...</td>\n      <td>4420</td>\n      <td>None</td>\n      <td>[Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πολ...</td>\n      <td>[[Ἀσιανός, γῆ, σχῆμα, θηβαία, πόλις, ἑδνόω, πο...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>[[Τροία, πράσσω, μηδείς, ὅδε, αὐχέω, πράσσω, δ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgl = pd.read_json(\"../data/large_data/cgl.json\")\n",
    "cgl.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cgl_embeddings = pickle.load(open(\"../data/large_data/cgl_embeddings.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "5000"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(1, len(cgl_embeddings[1])+1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[('εἰμί', 1),\n ('οὗτος', 2),\n ('λέγω', 3),\n ('ἔχω', 4),\n ('γίγνομαι', 5),\n ('πολύς', 6),\n ('ἄλλος', 7),\n ('αὐτός', 8),\n ('πᾶς', 9),\n ('ποιέω', 10)]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = dict(zip(cgl_embeddings[1],range(1, len(cgl_embeddings[1])+1)))\n",
    "list(word_index.items())[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# we will generate the concordances again, now focusing on words in the embeddings only\n",
    "def get_concordances(wordlist, keyword, window, vocabulary=None):\n",
    "    half = int(window / 2)\n",
    "    if vocabulary != None:\n",
    "        wordlist = [w for w in wordlist if w in vocabulary]\n",
    "    keyword_indices = [el[0] for el in enumerate(wordlist) if el[1]==keyword]\n",
    "    concordances = [wordlist[i-half:i+half+1] for i in keyword_indices]\n",
    "    concordances = [c for c in concordances if len(c)==window]\n",
    "    return concordances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "cgl[\"conc_lype\"] = cgl[\"lemmata_repl\"].apply(lambda x: get_concordances(x, \"λύπ*\", 31, vocabulary=cgl_embeddings[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "concs_series = cgl.apply(lambda row: [(row[\"author_id\"], conc) for conc in row[\"conc_lype\"]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tlg0003', ['ἐπικουρία', 'ποιέω', 'μέγας', 'δέχομαι', 'μαρτύριον', 'χάρις', 'κατατίθημι', 'ναυτικός', 'κτέομαι', 'πολύς', 'σκέπτομαι', 'εὐπραξία', 'σπάνιος', 'τὶς', 'πολέμιος', 'λύπ*', 'πολύς', 'χρῆμα', 'χάρις', 'τιμάω', 'δύναμις', 'προσγίγνομαι', 'οὗτος', 'πάρειμι', 'κίνδυνος', 'δαπάνη', 'φέρω', 'πολύς', 'ἀρετή', 'ἐπαμύνω', 'χάρις']), ('tlg0003', ['τοιοῦτος', 'πόλις', 'Λακεδαιμόνιος', 'οἴομαι', 'ἡσυχία', 'ἄνθρωπος', 'πολύς', 'ἀρκέω', 'παρασκευή', 'δίκαιος', 'πράσσω', 'γνώμη', 'ἀδικέω', 'δῆλος', 'εἰμί', 'λύπ*', 'ἄλλος', 'αὐτός', 'ἀμύνω', 'βλάπτω', 'ἴσος', 'νέμω', 'πόλις', 'ὅμοιος', 'τυγχάνω', 'οὗτος', 'δηλόω', 'ἐπιτήδευμα', 'εἰμί', 'ἀνάγκη', 'τέχνη']), ('tlg0003', ['πᾶς', 'μέγας', 'κίνδυνος', 'τίθημι', 'Λακεδαιμόνιος', 'Πελοπόννησος', 'πόλις', 'ὠφέλιμος', 'καθίστημι', 'ἐξηγέομαι', 'ὑπομένω', 'πᾶς', 'ἡγεμονία', 'οἶδα', 'ἥσσων', 'λύπ*', 'γίγνομαι', 'συμμαχέω', 'ἄρχω', 'αὐτός', 'κινδυνεύω', 'θαυμαστός', 'οὐδείς', 'ποιέω', 'ἀνθρώπειος', 'τρόπος', 'ἀρχή', 'δέχομαι', 'οὗτος', 'ἀνίημι', 'μέγας'])]\n"
     ]
    }
   ],
   "source": [
    "concs_tups = [conc for conclist in concs_series for conc in conclist]\n",
    "print(concs_tups[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[('tlg0003',\n  array([2877,   10,   18,  235, 2049,  193, 1264,  690,  421,    6,  452,\n         4380, 2096,   22,  124,  208,    6,   88,  193,  306,   79, 1498,\n            2,   92,  239, 1419,   63,    6,   97, 4892,  193])),\n ('tlg0003',\n  array([  17,   13,  114,   45,  613,   24,    6, 1125,  870,   56,   57,\n          189,  145,   89,    1,  208,    7,    8,  605,  488,  130,  572,\n           13,  133,   74,    2,  319,  798,    1,   52,  153])),\n ('tlg0003',\n  array([   9,   18,  239,   83,  114,  711,   13,  812,  142, 2251,  529,\n            9, 1616,   31,  134,  208,    5,  681,   84,    8,  409,  629,\n           15,   10, 2497,   68,   41,  235,    2, 1163,   18]))]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concs_tups = [(conc[0],  np.array([word_index[w] for w in conc[1]])) for conc in concs_tups]\n",
    "concs_tups[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "indices = np.arange(len(concs_tups))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "data = np.array([conc[1] for conc in concs_tups])\n",
    "labels = []\n",
    "for conc in concs_tups:\n",
    "    if conc[0] == \"tlg0086\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "labels = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "data = data[indices]\n",
    "labels = labels[indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "training_samples = int(len(data) * 0.75)\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples:]\n",
    "y_val = labels[training_samples:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "                   0          1         2         3         4         5    \\\nεἰμί         40.921943  23.975110  6.083791  1.724597  0.787708  1.395476   \nοὗτος        40.370998  23.444483  5.179671  1.611451  0.341264  1.735556   \nλέγω         39.001855  22.120811  3.711950  0.918392  1.452316  0.077037   \nἔχω          39.804302  23.024422  6.199601  2.275942  0.625015  1.243543   \nγίγνομαι     39.347879  22.489298  5.427730  1.608740 -0.299176  1.453300   \n...                ...        ...       ...       ...       ...       ...   \nκύαθος        2.306894  -1.252014  1.967848  0.639823 -0.830738  1.400087   \nσκυτεύς       2.426349  -1.921372  0.401636 -0.442950 -0.050278  0.079601   \nπαραμίγνυμι   2.460930  -1.073599  2.207248  0.563545 -0.814028  1.938490   \nὀφθαλμία      1.968229  -1.475017  1.460325 -0.047004 -0.329035  0.401820   \nκριτία        3.024949  -2.190102 -0.413723 -0.793175  0.007401  0.291926   \n\n                   6         7         8         9    ...       140       141  \\\nεἰμί         10.085121 -3.512090 -2.466157 -0.479203  ...  0.135525  0.116194   \nοὗτος         9.830402 -3.353345 -2.345492 -0.181414  ...  0.139695  0.078060   \nλέγω          9.391213 -2.759150 -2.398183  0.214704  ... -0.031307  0.068023   \nἔχω           9.147309 -3.485462 -2.581793 -0.275819  ...  0.024101  0.063533   \nγίγνομαι      8.521668 -3.282159 -2.755167 -0.361946  ...  0.017706  0.150147   \n...                ...       ...       ...       ...  ...       ...       ...   \nκύαθος        0.623265 -0.022984  1.364765 -1.015133  ...  0.029445  0.035054   \nσκυτεύς       1.183014 -0.539222  0.169868  0.727299  ... -0.379041  0.069706   \nπαραμίγνυμι   0.646300 -0.572682  2.623897 -1.114314  ... -0.005971 -0.170639   \nὀφθαλμία      0.145133 -0.578576 -0.902634  0.095910  ... -0.229633 -0.162759   \nκριτία        0.928121 -0.831658  0.027614  0.053107  ...  0.076820  0.334096   \n\n                  142       143       144       145       146       147  \\\nεἰμί         0.038779  0.028518  0.048852  0.063003 -0.006917 -0.285075   \nοὗτος        0.127660  0.069392  0.060385  0.249957  0.070054 -0.194425   \nλέγω         0.000057  0.069156  0.111072  0.038494  0.002585 -0.019338   \nἔχω          0.134114  0.179058  0.043486  0.113336 -0.036198 -0.342098   \nγίγνομαι    -0.100498  0.024932 -0.241511  0.180704 -0.044182 -0.225451   \n...               ...       ...       ...       ...       ...       ...   \nκύαθος      -0.064084 -0.022086 -0.026919 -0.029758 -0.059165  0.081717   \nσκυτεύς      0.277146  0.071542 -0.010878  0.112946 -0.114023  0.315502   \nπαραμίγνυμι -0.140238  0.136425  0.311922  0.270307 -0.047148 -0.198601   \nὀφθαλμία    -0.336879 -0.035314  0.135483 -0.145982  0.128570 -0.032265   \nκριτία       0.122024  0.005462 -0.073365  0.084474 -0.021100 -0.041049   \n\n                  148       149  \nεἰμί         0.083432  0.050213  \nοὗτος       -0.004014  0.040241  \nλέγω         0.269553 -0.130885  \nἔχω          0.209940 -0.073624  \nγίγνομαι    -0.009623  0.082624  \n...               ...       ...  \nκύαθος       0.070341  0.065586  \nσκυτεύς     -0.062303 -0.036280  \nπαραμίγνυμι -0.085457  0.311602  \nὀφθαλμία    -0.125454 -0.178760  \nκριτία      -0.171185 -0.437135  \n\n[5000 rows x 150 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>140</th>\n      <th>141</th>\n      <th>142</th>\n      <th>143</th>\n      <th>144</th>\n      <th>145</th>\n      <th>146</th>\n      <th>147</th>\n      <th>148</th>\n      <th>149</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>εἰμί</th>\n      <td>40.921943</td>\n      <td>23.975110</td>\n      <td>6.083791</td>\n      <td>1.724597</td>\n      <td>0.787708</td>\n      <td>1.395476</td>\n      <td>10.085121</td>\n      <td>-3.512090</td>\n      <td>-2.466157</td>\n      <td>-0.479203</td>\n      <td>...</td>\n      <td>0.135525</td>\n      <td>0.116194</td>\n      <td>0.038779</td>\n      <td>0.028518</td>\n      <td>0.048852</td>\n      <td>0.063003</td>\n      <td>-0.006917</td>\n      <td>-0.285075</td>\n      <td>0.083432</td>\n      <td>0.050213</td>\n    </tr>\n    <tr>\n      <th>οὗτος</th>\n      <td>40.370998</td>\n      <td>23.444483</td>\n      <td>5.179671</td>\n      <td>1.611451</td>\n      <td>0.341264</td>\n      <td>1.735556</td>\n      <td>9.830402</td>\n      <td>-3.353345</td>\n      <td>-2.345492</td>\n      <td>-0.181414</td>\n      <td>...</td>\n      <td>0.139695</td>\n      <td>0.078060</td>\n      <td>0.127660</td>\n      <td>0.069392</td>\n      <td>0.060385</td>\n      <td>0.249957</td>\n      <td>0.070054</td>\n      <td>-0.194425</td>\n      <td>-0.004014</td>\n      <td>0.040241</td>\n    </tr>\n    <tr>\n      <th>λέγω</th>\n      <td>39.001855</td>\n      <td>22.120811</td>\n      <td>3.711950</td>\n      <td>0.918392</td>\n      <td>1.452316</td>\n      <td>0.077037</td>\n      <td>9.391213</td>\n      <td>-2.759150</td>\n      <td>-2.398183</td>\n      <td>0.214704</td>\n      <td>...</td>\n      <td>-0.031307</td>\n      <td>0.068023</td>\n      <td>0.000057</td>\n      <td>0.069156</td>\n      <td>0.111072</td>\n      <td>0.038494</td>\n      <td>0.002585</td>\n      <td>-0.019338</td>\n      <td>0.269553</td>\n      <td>-0.130885</td>\n    </tr>\n    <tr>\n      <th>ἔχω</th>\n      <td>39.804302</td>\n      <td>23.024422</td>\n      <td>6.199601</td>\n      <td>2.275942</td>\n      <td>0.625015</td>\n      <td>1.243543</td>\n      <td>9.147309</td>\n      <td>-3.485462</td>\n      <td>-2.581793</td>\n      <td>-0.275819</td>\n      <td>...</td>\n      <td>0.024101</td>\n      <td>0.063533</td>\n      <td>0.134114</td>\n      <td>0.179058</td>\n      <td>0.043486</td>\n      <td>0.113336</td>\n      <td>-0.036198</td>\n      <td>-0.342098</td>\n      <td>0.209940</td>\n      <td>-0.073624</td>\n    </tr>\n    <tr>\n      <th>γίγνομαι</th>\n      <td>39.347879</td>\n      <td>22.489298</td>\n      <td>5.427730</td>\n      <td>1.608740</td>\n      <td>-0.299176</td>\n      <td>1.453300</td>\n      <td>8.521668</td>\n      <td>-3.282159</td>\n      <td>-2.755167</td>\n      <td>-0.361946</td>\n      <td>...</td>\n      <td>0.017706</td>\n      <td>0.150147</td>\n      <td>-0.100498</td>\n      <td>0.024932</td>\n      <td>-0.241511</td>\n      <td>0.180704</td>\n      <td>-0.044182</td>\n      <td>-0.225451</td>\n      <td>-0.009623</td>\n      <td>0.082624</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>κύαθος</th>\n      <td>2.306894</td>\n      <td>-1.252014</td>\n      <td>1.967848</td>\n      <td>0.639823</td>\n      <td>-0.830738</td>\n      <td>1.400087</td>\n      <td>0.623265</td>\n      <td>-0.022984</td>\n      <td>1.364765</td>\n      <td>-1.015133</td>\n      <td>...</td>\n      <td>0.029445</td>\n      <td>0.035054</td>\n      <td>-0.064084</td>\n      <td>-0.022086</td>\n      <td>-0.026919</td>\n      <td>-0.029758</td>\n      <td>-0.059165</td>\n      <td>0.081717</td>\n      <td>0.070341</td>\n      <td>0.065586</td>\n    </tr>\n    <tr>\n      <th>σκυτεύς</th>\n      <td>2.426349</td>\n      <td>-1.921372</td>\n      <td>0.401636</td>\n      <td>-0.442950</td>\n      <td>-0.050278</td>\n      <td>0.079601</td>\n      <td>1.183014</td>\n      <td>-0.539222</td>\n      <td>0.169868</td>\n      <td>0.727299</td>\n      <td>...</td>\n      <td>-0.379041</td>\n      <td>0.069706</td>\n      <td>0.277146</td>\n      <td>0.071542</td>\n      <td>-0.010878</td>\n      <td>0.112946</td>\n      <td>-0.114023</td>\n      <td>0.315502</td>\n      <td>-0.062303</td>\n      <td>-0.036280</td>\n    </tr>\n    <tr>\n      <th>παραμίγνυμι</th>\n      <td>2.460930</td>\n      <td>-1.073599</td>\n      <td>2.207248</td>\n      <td>0.563545</td>\n      <td>-0.814028</td>\n      <td>1.938490</td>\n      <td>0.646300</td>\n      <td>-0.572682</td>\n      <td>2.623897</td>\n      <td>-1.114314</td>\n      <td>...</td>\n      <td>-0.005971</td>\n      <td>-0.170639</td>\n      <td>-0.140238</td>\n      <td>0.136425</td>\n      <td>0.311922</td>\n      <td>0.270307</td>\n      <td>-0.047148</td>\n      <td>-0.198601</td>\n      <td>-0.085457</td>\n      <td>0.311602</td>\n    </tr>\n    <tr>\n      <th>ὀφθαλμία</th>\n      <td>1.968229</td>\n      <td>-1.475017</td>\n      <td>1.460325</td>\n      <td>-0.047004</td>\n      <td>-0.329035</td>\n      <td>0.401820</td>\n      <td>0.145133</td>\n      <td>-0.578576</td>\n      <td>-0.902634</td>\n      <td>0.095910</td>\n      <td>...</td>\n      <td>-0.229633</td>\n      <td>-0.162759</td>\n      <td>-0.336879</td>\n      <td>-0.035314</td>\n      <td>0.135483</td>\n      <td>-0.145982</td>\n      <td>0.128570</td>\n      <td>-0.032265</td>\n      <td>-0.125454</td>\n      <td>-0.178760</td>\n    </tr>\n    <tr>\n      <th>κριτία</th>\n      <td>3.024949</td>\n      <td>-2.190102</td>\n      <td>-0.413723</td>\n      <td>-0.793175</td>\n      <td>0.007401</td>\n      <td>0.291926</td>\n      <td>0.928121</td>\n      <td>-0.831658</td>\n      <td>0.027614</td>\n      <td>0.053107</td>\n      <td>...</td>\n      <td>0.076820</td>\n      <td>0.334096</td>\n      <td>0.122024</td>\n      <td>0.005462</td>\n      <td>-0.073365</td>\n      <td>0.084474</td>\n      <td>-0.021100</td>\n      <td>-0.041049</td>\n      <td>-0.171185</td>\n      <td>-0.437135</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 150 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = cgl_embeddings[3]\n",
    "embedding_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 31, 150)           750000    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4650)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                148832    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 898,865\n",
      "Trainable params: 898,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,  150, input_length=31))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 5ms/step - loss: 1.1336 - acc: 0.5684 - val_loss: 0.6552 - val_acc: 0.6000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4008 - acc: 0.8094 - val_loss: 0.5959 - val_acc: 0.6737\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2102 - acc: 0.9205 - val_loss: 0.5631 - val_acc: 0.7053\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0841 - acc: 0.9848 - val_loss: 1.2212 - val_acc: 0.5228\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0632 - acc: 0.9778 - val_loss: 2.1046 - val_acc: 0.6421\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0403 - acc: 0.9895 - val_loss: 0.7022 - val_acc: 0.7053\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.7742 - val_acc: 0.6596\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0403 - acc: 0.9836 - val_loss: 0.7485 - val_acc: 0.7193\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7888 - val_acc: 0.7228\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9883 - val_loss: 0.7718 - val_acc: 0.7123\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0_EXTRACTING-CORPORA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pipa_venv",
   "language": "python",
   "display_name": "pipa_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}